{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:23:18.447627Z",
     "start_time": "2018-03-27T01:23:18.418676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:16.404135Z",
     "start_time": "2018-03-27T01:26:16.325015Z"
    }
   },
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from scipy.misc import imread\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "from model.nms.nms_wrapper import nms\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.utils.net_utils import save_net, load_net, vis_detections\n",
    "from model.utils.blob import im_list_to_blob\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:16.906558Z",
     "start_time": "2018-03-27T01:26:16.793994Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _get_image_blob(im):\n",
    "    \"\"\"Converts an image into a network input.\n",
    "    Arguments:\n",
    "    im (ndarray): a color image in BGR order\n",
    "    Returns:\n",
    "    blob (ndarray): a data blob holding an image pyramid\n",
    "    im_scale_factors (list): list of image scales (relative to im) used\n",
    "      in the image pyramid\n",
    "    \"\"\"\n",
    "    im_orig = im.astype(np.float32, copy=True)\n",
    "    im_orig -= cfg.PIXEL_MEANS\n",
    "\n",
    "    im_shape = im_orig.shape\n",
    "    im_size_min = np.min(im_shape[0:2])\n",
    "    im_size_max = np.max(im_shape[0:2])\n",
    "\n",
    "    processed_ims = []\n",
    "    im_scale_factors = []\n",
    "\n",
    "    for target_size in cfg.TEST.SCALES:\n",
    "        im_scale = float(target_size) / float(im_size_min)\n",
    "        # Prevent the biggest axis from being more than MAX_SIZE\n",
    "        if np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:\n",
    "            im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)\n",
    "        im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,interpolation=cv2.INTER_LINEAR)\n",
    "        im_scale_factors.append(im_scale)\n",
    "        processed_ims.append(im)\n",
    "\n",
    "    # Create a blob to hold the input images\n",
    "    blob = im_list_to_blob(processed_ims)\n",
    "\n",
    "    return blob, np.array(im_scale_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:17.021962Z",
     "start_time": "2018-03-27T01:26:16.979693Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_from_file(\"cfgs/res101.yml\")\n",
    "set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]']\n",
    "cfg_from_list(set_cfgs)\n",
    "np.random.seed(cfg.RNG_SEED)\n",
    "load_model_path = os.path.join(\"models/res101/holly/good_models/faster_rcnn_1_1_117000.pth\")\n",
    "holly_classes = np.asarray(['__background__', 'head'])\n",
    "isCuda = True\n",
    "cfg.CUDA = isCuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:17.474732Z",
     "start_time": "2018-03-27T01:26:17.432787Z"
    }
   },
   "outputs": [],
   "source": [
    "def reload_model(opruneModelPath, weightsPTH=None):\n",
    "    fasterRCNN = resnet(holly_classes, 101, pretrained=False, class_agnostic=False)\n",
    "    fasterRCNN = torch.load(opruneModelPath)\n",
    "    if not weightsPTH is None:\n",
    "        checkpoint = torch.load(weightsPTH)\n",
    "        fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "        if 'pooling_mode' in checkpoint.keys():\n",
    "            cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    return fasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:21.639692Z",
     "start_time": "2018-03-27T01:26:21.611047Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_omodel(checkpoint_path):\n",
    "    fasterRCNN = resnet(holly_classes, 101, pretrained=False, class_agnostic=False)\n",
    "    fasterRCNN.create_architecture()\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "    if 'pooling_mode' in checkpoint.keys():\n",
    "        cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    return fasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:29.807893Z",
     "start_time": "2018-03-27T01:26:21.894357Z"
    }
   },
   "outputs": [],
   "source": [
    "fasterRCNN = load_omodel(load_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:35.051306Z",
     "start_time": "2018-03-27T01:26:34.889810Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getDiff(old_tensor, new_tensor, seq, detail=False):\n",
    "    total_difference = 0\n",
    "    diff = 0\n",
    "    original = 0  \n",
    "    if \"Conv2d\" in str(old_tensor) and not hasattr(old_tensor, \"__getitem__\") :\n",
    "        old_shape = old_tensor.weight.shape[0]\n",
    "        new_shape = new_tensor.weight.shape[0]\n",
    "        diff = old_shape - new_shape\n",
    "        original += old_shape\n",
    "        total_difference += diff\n",
    "        if detail:\n",
    "            print(str(e_old) + \"Difference = {}\".format(diff))\n",
    "    elif \"Sequential\" in str(old_tensor) and hasattr(old_tensor, \"__getitem__\"):\n",
    "        for j,b in enumerate(old_tensor):\n",
    "            bn_old = vars(b)\n",
    "            bn_new = vars(new_tensor[j])\n",
    "            convs_old = bn_old[\"_modules\"]\n",
    "            convs_new = bn_new[\"_modules\"]\n",
    "            for k,v in convs_old.items():\n",
    "                if \"conv\" in k:\n",
    "                    old_shape = v.weight.shape[0]\n",
    "                    original += old_shape\n",
    "                    new_shape = convs_new[k].weight.shape[0]\n",
    "                    diff = old_shape - new_shape\n",
    "                    if detail:\n",
    "                        print(\"S {}/ B {}/ {} Difference = {}\".format(seq, j, k, diff))\n",
    "                    total_difference += diff\n",
    "    return original, total_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:35.197498Z",
     "start_time": "2018-03-27T01:26:35.177815Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_cuda(isCuda, tensor):\n",
    "    if isCuda:\n",
    "        return tensor.cuda()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:35.932602Z",
     "start_time": "2018-03-27T01:26:35.861248Z"
    }
   },
   "outputs": [],
   "source": [
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "im_data = make_cuda(isCuda, im_data)\n",
    "im_info = make_cuda(isCuda, im_info)\n",
    "num_boxes = make_cuda(isCuda, num_boxes)\n",
    "gt_boxes = make_cuda(isCuda, gt_boxes)\n",
    "\n",
    "  # make variable\n",
    "im_data = Variable(im_data, volatile=True)\n",
    "im_info = Variable(im_info, volatile=True)\n",
    "num_boxes = Variable(num_boxes, volatile=True)\n",
    "gt_boxes = Variable(gt_boxes, volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:39.009361Z",
     "start_time": "2018-03-27T01:26:37.353409Z"
    },
    "code_folding": [
     0,
     3,
     12,
     25,
     37,
     47,
     59,
     69,
     79,
     88,
     94,
     113
    ]
   },
   "outputs": [],
   "source": [
    "def getNumpy(tensor):\n",
    "    return tensor.data.cpu().numpy()\n",
    "\n",
    "def sortFilters(filters):\n",
    "    #Sort filters by L1 Norm\n",
    "    c = filters.reshape(-1, filters.shape[0])\n",
    "    c = np.linalg.norm(c, ord=1, axis=0)\n",
    "    d = np.zeros([2, c.shape[0]])\n",
    "    i = np.argsort(c)\n",
    "    d[0,:] = i\n",
    "    d[1,:] = c[i]\n",
    "    return d\n",
    "def removeFilters(filters, percent, threshold=None):\n",
    "    #Remove filters from numpy \n",
    "    t = threshold\n",
    "    if threshold is None:\n",
    "        t = np.median(filters[1,:]) - np.std(filters[1,:])\n",
    "    mask = filters[1, :] > t\n",
    "    numRemoved_1 = mask.sum()\n",
    "    numRemoved_2 = int(numRemoved_1 * ((100. - percent) / 100.))\n",
    "    numOfZeros = numRemoved_1 - numRemoved_2\n",
    "    newFilters = filters[:,numRemoved_2:].copy()\n",
    "    newFilters[1, 0:numOfZeros] =0\n",
    "    return newFilters\n",
    "\n",
    "def removePercent(filters, KeepPercent, PrunePercent):\n",
    "    #Remove filters from numpy \n",
    "    numOfRemove = filters.shape[1] * PrunePercent / 100.\n",
    "    numRemoved_1 = int(numOfRemove)\n",
    "    numRemoved_2 = int(numRemoved_1 * ((100. - KeepPercent) / 100.))\n",
    "    numOfZeros = numRemoved_1 - numRemoved_2\n",
    "    newFilters = filters[:,numRemoved_2:].copy()\n",
    "    print(\"NumOfZeros:\")\n",
    "    print(numOfZeros)\n",
    "    newFilters[1, 0:numOfZeros] =0\n",
    "    return newFilters\n",
    "\n",
    "def sortRecoverFilters(l1Array, filters):\n",
    "    #Recover the order of the pruned filters\n",
    "    b = np.argsort(l1Array[0, :])\n",
    "    c = l1Array[:,b]\n",
    "    c = c[0,:].astype(int)\n",
    "    shape = np.asarray(filters.shape)\n",
    "    shape[0] = c.shape[0]\n",
    "    newFilters = np.zeros(shape)\n",
    "    newFilters = filters[c,:,:,:]\n",
    "    return newFilters\n",
    "def sortRecoverBatch(bn_tensor, index):\n",
    "    #Batch pruning \n",
    "    index.sort()\n",
    "    bn_rmean = bn_tensor.running_mean.cpu().numpy()\n",
    "    bn_tensor.running_mean = torch.from_numpy(bn_rmean[index]).float().cuda()\n",
    "    bn_rvar = bn_tensor.running_var.cpu().numpy()\n",
    "    bn_tensor.running_var = torch.from_numpy(bn_rvar[index]).float().cuda()\n",
    "    bn_weight = bn_tensor.weight.data.cpu().numpy()\n",
    "    bn_tensor.weight.data = torch.from_numpy(bn_weight[index]).float().cuda()\n",
    "    bn_bias = bn_tensor.bias.data.cpu().numpy()\n",
    "    bn_tensor.bias.data = torch.from_numpy(bn_bias[index]).float().cuda()\n",
    "\n",
    "def pruneConvLayers(tensor, percent = 10, threshold = None):\n",
    "    #Prune out channels of convolutional layers\n",
    "    filters = getNumpy(tensor.weight)\n",
    "    d = sortFilters(filters)\n",
    "    e = removeFilters(d, percent, threshold)\n",
    "    f = sortRecoverFilters(e, filters)\n",
    "    tensor.weight.data = torch.from_numpy(f).float().cuda()\n",
    "    tensor.out_channels = f.shape[0]\n",
    "    rindexes = e[0,:].astype(int).copy()\n",
    "    return tensor, rindexes\n",
    "def pruneConvPercent(tensor, KeepPercent = 10, PrunePercent=10):\n",
    "    #Prune out channels of convolutional layers\n",
    "    filters = getNumpy(tensor.weight)\n",
    "    d = sortFilters(filters)\n",
    "    e = removePercent(d, KeepPercent, PrunePercent)\n",
    "    f = sortRecoverFilters(e, filters)\n",
    "    tensor.weight.data = torch.from_numpy(f).float().cuda()\n",
    "    tensor.out_channels = f.shape[0]\n",
    "    rindexes = e[0,:].astype(int).copy()\n",
    "    return tensor, rindexes\n",
    "def pruneConvLowest(tensor, numKeep):\n",
    "    filters = getNumpy(tensor.weight)\n",
    "    d = sortFilters(filters)\n",
    "    e = d[:,0:numKeep]\n",
    "    f = sortRecoverFilters(e, filters)\n",
    "    tensor.weight.data = torch.from_numpy(f).float().cuda()\n",
    "    tensor.out_channels = f.shape[0]\n",
    "    rindexes = e[0,:].astype(int).copy()\n",
    "    return tensor, rindexes\n",
    "def pruneConvWithIndexes(tensor, rindexes):\n",
    "    #Prune out channels of convolutional layers using indexes\n",
    "    filters = getNumpy(tensor.weight)\n",
    "    tensor.weight.data = torch.from_numpy(filters[rindexes]).float().cuda()\n",
    "    tensor.out_channels = tensor.weight.data.shape[0]\n",
    "    return tensor, rindexes\n",
    "def pruneNextLayer(nextLayerTensor, prevOutput, rindexes=None):\n",
    "    #Prune input channels of everything\n",
    "    if \"BatchNorm\" in str(nextLayerTensor):\n",
    "        nextLayerTensor.num_features = prevOutput\n",
    "        sortRecoverBatch(nextLayerTensor, rindexes)\n",
    "    elif \"Conv2d\" in str(nextLayerTensor):\n",
    "        nextLayerTensor.in_channels = prevOutput\n",
    "        nextConvWeight = getNumpy(nextLayerTensor.weight)\n",
    "        if not rindexes is None:\n",
    "            c = nextConvWeight[:,rindexes,:,:]\n",
    "        else:\n",
    "            c = nextConvWeight\n",
    "        nextLayerTensor.weight.data = torch.from_numpy(c).float().cuda()\n",
    "    elif \"Linear\" in str(nextLayerTensor):\n",
    "        n = getNumpy(nextLayerTensor.weight)\n",
    "        fc = n[:,r]\n",
    "        nextLayerTensor.in_features = fc.shape[1]\n",
    "        nextLayerTensor.weight.data = torch.from_numpy(fc).float().cuda()\n",
    "    return nextLayerTensor\n",
    "def prune_bottleneck(bottlenecks, prevOutput, rindexesX, keeplast=False):\n",
    "    for i,bottleneck in enumerate(bottlenecks):\n",
    "        #Conv1 Prune\n",
    "        currentTensor = pruneNextLayer(bottleneck.conv1, prevOutput, rindexesX) #Conv1 Input channels Prune\n",
    "        currentTensor, rindexes = pruneConvLayers(bottleneck.conv1) #Conv1 Output channels Prune\n",
    "        currentTensor           = pruneNextLayer(bottleneck.bn1, currentTensor.out_channels, rindexes) #BN1 prune\n",
    "        \n",
    "        #Conv2 Prune\n",
    "        currentTensor           = pruneNextLayer(bottleneck.conv2, currentTensor.num_features, rindexes) #Conv2 Input channels Prune\n",
    "        currentTensor, rindexes = pruneConvLayers(bottleneck.conv2) #Conv2 Input channels Prune\n",
    "        currentTensor           = pruneNextLayer(bottleneck.bn2, currentTensor.out_channels, rindexes) #BN2 prune\n",
    "        #Shortcut + conv2\n",
    "        currentTensor           = pruneNextLayer(bottleneck.conv3, currentTensor.num_features, rindexes) #Conv3 input channels\n",
    "        \n",
    "        #Prune shortcut first\n",
    "        if not bottleneck.downsample is None:\n",
    "            b_neck = bottleneck.downsample\n",
    "            pruneNextLayer(b_neck[0], prevOutput, rindexesX) #Shortcut Input Channels\n",
    "            shorcutconv, rindexes = pruneConvLayers(b_neck[0]) #Shortcut output channels\n",
    "            pruneNextLayer(b_neck[1], b_neck[0].out_channels, rindexes) #bn1 of shorcut\n",
    "        \n",
    "            if not keeplast:\n",
    "                lastconv, rindexes = pruneConvWithIndexes(bottleneck.conv3, rindexes) #Conv3 output channels\n",
    "            else:\n",
    "                lastconv = bottleneck.conv3\n",
    "        else:\n",
    "            if not keeplast:\n",
    "                lastconv, rindexes = pruneConvLowest(bottleneck.conv3, len(rindexesX))\n",
    "            else:\n",
    "                lastconv = bottleneck.conv3\n",
    "            \n",
    "        lastbn = pruneNextLayer(bottleneck.bn3, currentTensor.out_channels, rindexes) #BN3 prune\n",
    "        num_output = lastconv.out_channels\n",
    "        rindexesX = rindexes\n",
    "    return bottleneck, num_output, rindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:39.570900Z",
     "start_time": "2018-03-27T01:26:39.456096Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pruneEverything():\n",
    "    percent = 10\n",
    "    prevIndex = 0\n",
    "    prevOutput = 3\n",
    "    rindexes = None\n",
    "    for i,e in enumerate(fasterRCNN.RCNN_base):\n",
    "        currentTensor = e\n",
    "        if \"Conv2d\" in str(currentTensor) and not hasattr(currentTensor, \"__getitem__\"):\n",
    "            if prevOutput != currentTensor.in_channels:\n",
    "                currentTensor = pruneNextLayer(currentTensor, prevOutput)\n",
    "            currentTensor, rindexes = pruneConvLayers(currentTensor, percent)\n",
    "            prevOutput = currentTensor.out_channels\n",
    "\n",
    "        elif \"BatchNorm\" in str(currentTensor) and not hasattr(currentTensor, \"__getitem__\"):\n",
    "            if prevOutput != currentTensor.num_features:\n",
    "                currentTensor = pruneNextLayer(currentTensor, prevOutput, rindexes)           \n",
    "            prevOutput = currentTensor.num_features\n",
    "        elif hasattr(currentTensor, \"__getitem__\"):\n",
    "            b, prevOutput, rindexes = prune_bottleneck(currentTensor, prevOutput, rindexes)\n",
    "\n",
    "        prevIndex = i\n",
    "        prevTensor = currentTensor\n",
    "\n",
    "    #Prune RoI pooling and FC classifiers\n",
    "    b = pruneNextLayer(fasterRCNN.RCNN_rpn.RPN_Conv, prevOutput, rindexes)\n",
    "    b, p, r = prune_bottleneck(fasterRCNN.RCNN_top[0], prevOutput, rindexes)\n",
    "    fc = pruneNextLayer(fasterRCNN.RCNN_bbox_pred, p, r)\n",
    "    cls_score = pruneNextLayer(fasterRCNN.RCNN_cls_score, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:40.015231Z",
     "start_time": "2018-03-27T01:26:39.804816Z"
    }
   },
   "outputs": [],
   "source": [
    "if isCuda:\n",
    "    fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:26:47.196466Z",
     "start_time": "2018-03-27T01:26:46.716867Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/livia/home/vision/lethanh/anaconda2/envs/py3ml/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/export/livia/home/vision/lethanh/workspace/faster-rcnn.pytorch/lib/model/rpn/rpn.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape)\n",
      "/export/livia/home/vision/lethanh/workspace/faster-rcnn.pytorch/lib/model/faster_rcnn/faster_rcnn.py:97: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_prob = F.softmax(cls_score)\n"
     ]
    }
   ],
   "source": [
    "im_file = os.path.join('images/img_head.jpeg')\n",
    "        # im = cv2.imread(im_file)\n",
    "im_in = np.array(imread(im_file))\n",
    "if len(im_in.shape) == 2:\n",
    "    im_in = im_in[:,:,np.newaxis]\n",
    "    im_in = np.concatenate((im_in,im_in,im_in), axis=2)\n",
    "      # rgb -> bgr\n",
    "im = im_in[:,:,::-1]\n",
    "blobs, im_scales = _get_image_blob(im)\n",
    "assert len(im_scales) == 1, \"Only single-image batch implemented\"\n",
    "im_blob = blobs\n",
    "im_info_np = np.array([[im_blob.shape[1], im_blob.shape[2], im_scales[0]]], dtype=np.float32)\n",
    "\n",
    "im_data_pt = torch.from_numpy(im_blob)\n",
    "im_data_pt = im_data_pt.permute(0, 3, 1, 2)\n",
    "im_info_pt = torch.from_numpy(im_info_np)\n",
    "\n",
    "im_data.data.resize_(im_data_pt.size()).copy_(im_data_pt)\n",
    "im_info.data.resize_(im_info_pt.size()).copy_(im_info_pt)\n",
    "gt_boxes.data.resize_(1, 1, 5).zero_()\n",
    "num_boxes.data.resize_(1).zero_()\n",
    "\n",
    "# pdb.set_trace()\n",
    "det_tic = time.time()\n",
    "\n",
    "rois, cls_prob, bbox_pred, \\\n",
    "rpn_loss_cls, rpn_loss_box, \\\n",
    "RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "scores = cls_prob.data\n",
    "boxes = rois.data[:, :, 1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T01:40:20.178763Z",
     "start_time": "2018-03-27T01:40:19.931817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasterRCNN.RCNN_base[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T20:43:10.874795Z",
     "start_time": "2018-03-26T20:43:10.761054Z"
    }
   },
   "outputs": [],
   "source": [
    "c1_fm = fm[0]\n",
    "block_fm1 = fm[1]\n",
    "block_fm2 = fm[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T21:25:59.282258Z",
     "start_time": "2018-03-26T21:25:59.215592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 38, 51])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T21:26:03.758631Z",
     "start_time": "2018-03-26T21:26:03.688761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 38, 51])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_fm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T21:26:04.715510Z",
     "start_time": "2018-03-26T21:26:04.632016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 38, 51])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_fm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T20:41:38.934313Z",
     "start_time": "2018-03-26T20:41:38.474572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrunePercent : 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_name_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a8fbe1eaab8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprunePercent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PrunePercent : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfasterRCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_name_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsPTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mb_1_1_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasterRCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCNN_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mb_1_1_conv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasterRCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCNN_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_name_model' is not defined"
     ]
    }
   ],
   "source": [
    "weightsPTH = \"./models/res101/holly/pruned_42000_1.pth\"\n",
    "prunePercent = [10, 12, 15 ,20]\n",
    "KeepPercent = 10\n",
    "for i in prunePercent:\n",
    "    print(\"PrunePercent : {}\".format(i))\n",
    "    fasterRCNN = reload_model(save_name_model, weightsPTH)\n",
    "    b_1_1_conv1 = fasterRCNN.RCNN_base[4][0].conv1\n",
    "    b_1_1_conv2 = fasterRCNN.RCNN_base[4][0].conv2\n",
    "    b_1_1_bn1 = fasterRCNN.RCNN_base[4][0].bn1\n",
    "    _, r = pruneConvPercent(b_1_1_conv1, KeepPercent, PrunePercent)\n",
    "    print(\"PruneFiltersNum : {}\".format(b_1_1_conv1.out_channels ))\n",
    "    pruneNextLayer(b_1_1_bn1, r.shape[0], r)\n",
    "    pruneNextLayer(b_1_1_conv2, r.shape[0], r)\n",
    "    evalNetwork(fasterRCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:35:07.317521Z",
     "start_time": "2018-03-26T19:35:07.231Z"
    }
   },
   "outputs": [],
   "source": [
    "fasterRCNN.RCNN_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T16:36:44.946145Z",
     "start_time": "2018-03-26T16:36:44.132533Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evalNetwork(modelFR):\n",
    "    modelFR.eval()\n",
    "    \n",
    "    cfg.TRAIN.USE_FLIPPED = False\n",
    "    imdb_name = \"holly_test\"\n",
    "    imdb, roidb, ratio_list, ratio_index = combined_roidb(imdb_name, False)\n",
    "    imdb.competition_mode(on=True)\n",
    "    \n",
    "    save_name = 'faster_rcnn_10'\n",
    "    num_images = len(imdb.image_index)\n",
    "    all_boxes = [[[] for _ in range(num_images)]\n",
    "               for _ in range(imdb.num_classes)]\n",
    "\n",
    "    output_dir = get_output_dir(imdb, save_name)\n",
    "\n",
    "    dataset = roibatchLoader(roidb, ratio_list, ratio_index, 1, \\\n",
    "                            imdb.num_classes, training=False, normalize = False)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                                shuffle=False, num_workers=0,\n",
    "                                pin_memory=True)\n",
    "    output_dir = \"/tmp/outTest\"\n",
    "    vis = False\n",
    "    thresh = 0.0\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    num_images = len(imdb.image_index)\n",
    "\n",
    "    start = time.time()\n",
    "    max_per_image = 100\n",
    "\n",
    "    im_dataC = torch.FloatTensor(1)\n",
    "    im_infoC = torch.FloatTensor(1)\n",
    "    num_boxesC = torch.LongTensor(1)\n",
    "    gt_boxesC = torch.FloatTensor(1)\n",
    "\n",
    "    # ship to cuda\n",
    "    im_dataC = make_cuda(isCuda, im_dataC)\n",
    "    im_infoC = make_cuda(isCuda, im_infoC)\n",
    "    num_boxesC = make_cuda(isCuda, num_boxesC)\n",
    "    gt_boxesC = make_cuda(isCuda, gt_boxesC)\n",
    "\n",
    "      # make variable\n",
    "    im_dataC = Variable(im_dataC, volatile=True)\n",
    "    im_infoC = Variable(im_infoC, volatile=True)\n",
    "    num_boxesC = Variable(num_boxesC, volatile=True)\n",
    "    gt_boxesC = Variable(gt_boxesC, volatile=True)\n",
    "\n",
    "    _t = {'im_detect': time.time(), 'misc': time.time()}\n",
    "    det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "    empty_array = np.transpose(np.array([[],[],[],[],[]]), (1,0))\n",
    "    for i in range(num_images):\n",
    "\n",
    "        data = next(data_iter)\n",
    "        im_dataC.data.resize_(data[0].size()).copy_(data[0])\n",
    "        im_infoC.data.resize_(data[1].size()).copy_(data[1])\n",
    "        gt_boxesC.data.resize_(data[2].size()).copy_(data[2])\n",
    "        num_boxesC.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "        det_tic = time.time()\n",
    "        rois, cls_prob, bbox_pred, \\\n",
    "        rpn_loss_cls, rpn_loss_box, \\\n",
    "        RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "        rois_label = modelFR(im_dataC, im_infoC, gt_boxesC, num_boxesC)\n",
    "\n",
    "        scores = cls_prob.data\n",
    "        boxes = rois.data[:, :, 1:5]\n",
    "\n",
    "        if cfg.TEST.BBOX_REG:\n",
    "              # Apply bounding-box regression deltas\n",
    "            box_deltas = bbox_pred.data\n",
    "            if cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED:\n",
    "              # Optionally normalize targets by a precomputed mean and stdev\n",
    "                if False:#args.class_agnostic:\n",
    "                    box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                               + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "                    box_deltas = box_deltas.view(1, -1, 4)\n",
    "                else:\n",
    "                    box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                               + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "                    box_deltas = box_deltas.view(1, -1, 4 * len(imdb.classes))\n",
    "\n",
    "            pred_boxes = bbox_transform_inv(boxes, box_deltas, 1)\n",
    "            pred_boxes = clip_boxes(pred_boxes, im_infoC.data, 1)\n",
    "        else:\n",
    "              # Simply repeat the boxes, once for each class\n",
    "            pred_boxes = np.tile(boxes, (1, scores.shape[1]))\n",
    "\n",
    "        pred_boxes /= data[1][0][2]\n",
    "\n",
    "        scores = scores.squeeze()\n",
    "        pred_boxes = pred_boxes.squeeze()\n",
    "        det_toc = time.time()\n",
    "        detect_time = det_toc - det_tic\n",
    "        misc_tic = time.time()\n",
    "        if vis:\n",
    "            im = cv2.imread(imdb.image_path_at(i))\n",
    "            im2show = np.copy(im)\n",
    "        for j in range(1, imdb.num_classes):\n",
    "            inds = torch.nonzero(scores[:,j]>thresh).view(-1)\n",
    "              # if there is det\n",
    "            if inds.numel() > 0:\n",
    "                cls_scores = scores[:,j][inds]\n",
    "                _, order = torch.sort(cls_scores, 0, True)\n",
    "                if False:#args.class_agnostic:\n",
    "                    cls_boxes = pred_boxes[inds, :]\n",
    "                else:\n",
    "                    cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "\n",
    "                cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                cls_dets = cls_dets[order]\n",
    "                keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                if vis:\n",
    "                    im2show = vis_detections(im2show, imdb.classes[j], cls_dets.cpu().numpy(), 0.3)\n",
    "                all_boxes[j][i] = cls_dets.cpu().numpy()\n",
    "            else:\n",
    "                all_boxes[j][i] = empty_array\n",
    "\n",
    "          # Limit to max_per_image detections *over all classes*\n",
    "        if max_per_image > 0:\n",
    "            image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                        for j in range(1, imdb.num_classes)])\n",
    "            if len(image_scores) > max_per_image:\n",
    "                image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "                for j in range(1, imdb.num_classes):\n",
    "                    keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                    all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "\n",
    "        misc_toc = time.time()\n",
    "        nms_time = misc_toc - misc_tic\n",
    "\n",
    "        sys.stdout.write('im_detect: {:d}/{:d} {:.3f}s {:.3f}s   \\r' \\\n",
    "          .format(i + 1, num_images, detect_time, nms_time))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if vis:\n",
    "            cv2.imwrite('result.png', im2show)\n",
    "            pdb.set_trace()\n",
    "\n",
    "    with open(det_file, 'wb+') as f:\n",
    "        pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print('Evaluating detections')\n",
    "    imdb.evaluate_detections(all_boxes, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T16:36:51.928454Z",
     "start_time": "2018-03-26T16:36:44.948167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset `HF__test` for training\n",
      "Set proposal method: gt\n",
      "Preparing training data...\n",
      "HF__test gt roidb loaded from /export/livia/home/vision/lethanh/workspace/faster-rcnn.pytorch/data/cache/HF__test_gt_roidb.pkl\n",
      "done\n",
      "im_detect: 1/1293 0.090s 0.001s   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/livia/home/vision/lethanh/workspace/faster-rcnn.pytorch/lib/model/rpn/rpn.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape)\n",
      "/export/livia/home/vision/lethanh/workspace/faster-rcnn.pytorch/lib/model/faster_rcnn/faster_rcnn.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_prob = F.softmax(cls_score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im_detect: 47/1293 0.081s 0.001s   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8ba2c7543aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevalNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasterRCNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b030a041e462>\u001b[0m in \u001b[0;36mevalNetwork\u001b[0;34m(modelFR)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBBOX_NORMALIZE_STDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBBOX_NORMALIZE_MEANS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3ml/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evalNetwork(fasterRCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:43:01.800869Z",
     "start_time": "2018-03-25T21:42:59.668029Z"
    }
   },
   "outputs": [],
   "source": [
    "save_name_model = os.path.join(\"./models/res101/holly/\", 'pruned_117000_1.p')\n",
    "torch.save(fasterRCNN, save_name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
